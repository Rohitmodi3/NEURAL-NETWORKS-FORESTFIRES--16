{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c6364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0113ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest =pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Documents\\\\rohit\\\\forestfires.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be1bb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a6b268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>92.3</td>\n",
       "      <td>85.3</td>\n",
       "      <td>488.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>29</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>92.3</td>\n",
       "      <td>88.9</td>\n",
       "      <td>495.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>24.1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>91.5</td>\n",
       "      <td>145.4</td>\n",
       "      <td>608.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sep</td>\n",
       "      <td>tue</td>\n",
       "      <td>91.0</td>\n",
       "      <td>129.5</td>\n",
       "      <td>692.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>63</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sep</td>\n",
       "      <td>sat</td>\n",
       "      <td>92.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>698.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>22.8</td>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "5   aug  sun  92.3   85.3  488.0  14.7  22.2  29   5.4   0.0  ...         0   \n",
       "6   aug  mon  92.3   88.9  495.6   8.5  24.1  27   3.1   0.0  ...         0   \n",
       "7   aug  mon  91.5  145.4  608.2  10.7   8.0  86   2.2   0.0  ...         0   \n",
       "8   sep  tue  91.0  129.5  692.6   7.0  13.1  63   5.4   0.0  ...         0   \n",
       "9   sep  sat  92.5   88.0  698.6   7.1  22.8  40   4.0   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "5         0         0         0         0         0         0         0   \n",
       "6         0         0         0         0         0         0         0   \n",
       "7         0         0         0         0         0         0         0   \n",
       "8         0         0         0         0         0         0         0   \n",
       "9         0         0         0         0         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "5         0          small  \n",
       "6         0          small  \n",
       "7         0          small  \n",
       "8         1          small  \n",
       "9         1          small  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forest.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd4a54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.0</td>\n",
       "      <td>166.9</td>\n",
       "      <td>752.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>41</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.0</td>\n",
       "      <td>166.9</td>\n",
       "      <td>752.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>41</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.0</td>\n",
       "      <td>166.9</td>\n",
       "      <td>752.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>21.1</td>\n",
       "      <td>71</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.0</td>\n",
       "      <td>166.9</td>\n",
       "      <td>752.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>62</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>35</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "507   aug  fri  91.0  166.9  752.6   7.1  25.9  41   3.6   0.0  ...         0   \n",
       "508   aug  fri  91.0  166.9  752.6   7.1  25.9  41   3.6   0.0  ...         0   \n",
       "509   aug  fri  91.0  166.9  752.6   7.1  21.1  71   7.6   1.4  ...         0   \n",
       "510   aug  fri  91.0  166.9  752.6   7.1  18.2  62   5.4   0.0  ...         0   \n",
       "511   aug  sun  81.6   56.7  665.6   1.9  27.8  35   2.7   0.0  ...         0   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "507         0         0         0         0         0         0         0   \n",
       "508         0         0         0         0         0         0         0   \n",
       "509         0         0         0         0         0         0         0   \n",
       "510         0         0         0         0         0         0         0   \n",
       "511         0         0         0         0         0         0         0   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "507         0          small  \n",
       "508         0          small  \n",
       "509         0          small  \n",
       "510         0          small  \n",
       "511         0          small  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forest.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e432452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "Forest.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29122431",
   "metadata": {},
   "source": [
    "Forest.dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014890fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c6cbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain', 'area', 'dayfri', 'daymon', 'daysat', 'daysun', 'daythu', 'daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', 'monthfeb', 'monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay', 'monthnov', 'monthoct', 'monthsep']\n"
     ]
    }
   ],
   "source": [
    "numerical_feature = Forest.describe(include = [\"int64\",\"float\"]).columns\n",
    "print(list(numerical_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4754848",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.pairplot(Forest[numerical_feature])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e00afb9",
   "metadata": {},
   "source": [
    "# Since number of columns are more, lets use PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f77f9f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = Forest.iloc[:,2:30]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(df1)\n",
    "df_norm = sc.transform(df1)\n",
    "df_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a9a0f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02,  4.98037274e-16, -2.73530281e-16],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02, -9.55928328e-15,  1.15055466e-15],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02,  2.58690766e-15, -5.66797432e-17],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01, -1.84247930e-16,  2.36645381e-16],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02, -2.30354869e-16,  2.72058887e-16],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  5.70142521e-17,  8.50237385e-17]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 28)\n",
    "pca_values = pca.fit_transform(df_norm)\n",
    "pca_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54995e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 1.95971390e-33])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = pca.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c1e8bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = np.cumsum(np.round(var, decimals = 4)*100)\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e19128f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(var1, color= 'Blue');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "719859be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>-0.926619</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>-0.892995</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>-0.297870</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.081757</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>1.523710</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.378420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>-0.723371</td>\n",
       "      <td>2.020419</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>0.161735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.087560</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>1.536581</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>-1.133422</td>\n",
       "      <td>-0.362287</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.818745</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.539642</td>\n",
       "      <td>-0.052958</td>\n",
       "      <td>1.898628</td>\n",
       "      <td>-1.441786</td>\n",
       "      <td>-0.821192</td>\n",
       "      <td>-1.205707</td>\n",
       "      <td>-0.698666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.794366</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>2.670485</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>-0.904232</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>1.340049</td>\n",
       "      <td>-0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342367</td>\n",
       "      <td>0.485571</td>\n",
       "      <td>0.580150</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>-0.970693</td>\n",
       "      <td>-1.353365</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>-1.212175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.921634</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>2.719216</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>-0.966939</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>1.290364</td>\n",
       "      <td>-0.177553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332816</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.122409</td>\n",
       "      <td>0.313948</td>\n",
       "      <td>0.211157</td>\n",
       "      <td>-0.777731</td>\n",
       "      <td>-1.736711</td>\n",
       "      <td>-1.154127</td>\n",
       "      <td>-1.230040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-1.620549</td>\n",
       "      <td>-0.978838</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>-0.408164</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>-1.398344</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-1.035533</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-0.216315</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.055548</td>\n",
       "      <td>-0.067502</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4.075907</td>\n",
       "      <td>-0.367441</td>\n",
       "      <td>-0.247152</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>6.792273</td>\n",
       "      <td>5.943666</td>\n",
       "      <td>-1.639583</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>4.953722</td>\n",
       "      <td>...</td>\n",
       "      <td>10.467443</td>\n",
       "      <td>-7.333036</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>8.870354</td>\n",
       "      <td>-1.074288</td>\n",
       "      <td>2.382433</td>\n",
       "      <td>1.042850</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1    0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2    0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3    3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4    2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -0.087560  0.153964  1.241810  1.536581  0.372425 -1.133422 -0.362287   \n",
       "513  0.794366 -0.083966  2.670485  0.284995  0.223323 -0.904232 -0.014849   \n",
       "514  0.921634 -0.264543  2.719216 -0.019643  0.242195 -0.966939 -0.118080   \n",
       "515 -1.620549 -0.978838  0.331987  1.256638 -0.408164  0.735698  0.815510   \n",
       "516  4.075907 -0.367441 -0.247152  0.979966  6.792273  5.943666 -1.639583   \n",
       "\n",
       "          pc8       pc9      pc10  ...       pc16      pc17      pc18  \\\n",
       "0   -0.019764  0.010161 -0.437314  ...  -0.197543 -0.021839  0.688958   \n",
       "1    0.041095 -0.548879  0.104500  ...  -2.503167  0.499649  0.563706   \n",
       "2   -2.159336 -0.090580  0.260888  ...  -2.545144 -0.658411 -0.423618   \n",
       "3   -0.250227 -0.620329 -1.343189  ...  -0.040887  0.017843  0.332572   \n",
       "4    0.303635  0.861126 -2.024719  ...   0.844431  1.014944 -0.618231   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "512  0.766946  0.818745 -0.289632  ...   0.300522  0.513876  0.539642   \n",
       "513  0.107226  1.340049 -0.147246  ...   0.342367  0.485571  0.580150   \n",
       "514  0.123010  1.290364 -0.177553  ...   0.332816  0.344047  0.122409   \n",
       "515 -1.398344  0.076379 -0.005814  ...  -0.011739 -1.035533 -0.774382   \n",
       "516  8.121827 -0.627980  4.953722  ...  10.467443 -7.333036  0.377340   \n",
       "\n",
       "         pc19      pc20      pc21      pc22      pc23      pc24  size_category  \n",
       "0    0.563603 -0.439596 -0.926619 -0.405425 -0.118719 -0.017933              0  \n",
       "1   -0.703319 -1.535718 -0.892995  0.836590  0.204975  0.290771              0  \n",
       "2    0.860550 -1.195230 -0.297870  0.743648  0.081757  0.345915              0  \n",
       "3    1.164745 -1.632741 -0.817618  1.523710 -0.342302 -0.378420              0  \n",
       "4    0.822853 -1.794109 -0.723371  2.020419 -0.545591  0.161735              0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "512 -0.052958  1.898628 -1.441786 -0.821192 -1.205707 -0.698666              1  \n",
       "513  0.384984  0.086251 -0.970693 -1.353365 -1.254890 -1.212175              1  \n",
       "514  0.313948  0.211157 -0.777731 -1.736711 -1.154127 -1.230040              1  \n",
       "515 -0.216315  0.515791  0.080575 -0.055548 -0.067502 -0.311027              0  \n",
       "516  8.870354 -1.074288  2.382433  1.042850  0.296436  0.125099              0  \n",
       "\n",
       "[517 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf = pd.concat([pd.DataFrame(pca_values[:,0:24], columns = ['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
    "                                                             'pc22','pc23','pc24']),\n",
    "                     Forest[['size_category']]], axis =1)\n",
    "finalDf.size_category.replace(('large', 'small'),(1,0), inplace=True)\n",
    "finalDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "536b687b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = finalDf.values\n",
    "X = array[:, 0:24]\n",
    "Y = array[:,24]\n",
    "\n",
    "X.reshape(-1, 1)\n",
    "Y.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3480402b",
   "metadata": {},
   "source": [
    "# Iteration 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff9ac5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 2s 15ms/step - loss: 0.7150 - accuracy: 0.4931 - val_loss: 0.6845 - val_accuracy: 0.5385\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.5762 - val_loss: 0.6608 - val_accuracy: 0.6026\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6759 - val_loss: 0.6489 - val_accuracy: 0.6603\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.7507 - val_loss: 0.6439 - val_accuracy: 0.6474\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7701 - val_loss: 0.6449 - val_accuracy: 0.6859\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.7784 - val_loss: 0.6506 - val_accuracy: 0.6859\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7729 - val_loss: 0.6550 - val_accuracy: 0.6923\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7756 - val_loss: 0.6578 - val_accuracy: 0.6923\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7729 - val_loss: 0.6609 - val_accuracy: 0.6859\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7729 - val_loss: 0.6648 - val_accuracy: 0.6859\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7729 - val_loss: 0.6675 - val_accuracy: 0.6859\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7756 - val_loss: 0.6660 - val_accuracy: 0.6859\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7784 - val_loss: 0.6707 - val_accuracy: 0.6859\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7784 - val_loss: 0.6690 - val_accuracy: 0.6859\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7839 - val_loss: 0.6656 - val_accuracy: 0.6795\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7867 - val_loss: 0.6684 - val_accuracy: 0.6795\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7895 - val_loss: 0.6629 - val_accuracy: 0.6859\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7895 - val_loss: 0.6659 - val_accuracy: 0.6859\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7922 - val_loss: 0.6635 - val_accuracy: 0.6923\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7922 - val_loss: 0.6630 - val_accuracy: 0.6923\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7950 - val_loss: 0.6615 - val_accuracy: 0.6987\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8033 - val_loss: 0.6557 - val_accuracy: 0.7115\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8061 - val_loss: 0.6545 - val_accuracy: 0.7051\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8061 - val_loss: 0.6511 - val_accuracy: 0.7051\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8089 - val_loss: 0.6474 - val_accuracy: 0.7179\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8116 - val_loss: 0.6461 - val_accuracy: 0.7179\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8144 - val_loss: 0.6471 - val_accuracy: 0.7372\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8144 - val_loss: 0.6438 - val_accuracy: 0.7372\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8144 - val_loss: 0.6396 - val_accuracy: 0.7372\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8172 - val_loss: 0.6409 - val_accuracy: 0.7436\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8199 - val_loss: 0.6386 - val_accuracy: 0.7308\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8199 - val_loss: 0.6389 - val_accuracy: 0.7308\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8199 - val_loss: 0.6380 - val_accuracy: 0.7372\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8199 - val_loss: 0.6380 - val_accuracy: 0.7500\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8255 - val_loss: 0.6336 - val_accuracy: 0.7500\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8283 - val_loss: 0.6264 - val_accuracy: 0.7692\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8310 - val_loss: 0.6238 - val_accuracy: 0.7692\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8310 - val_loss: 0.6265 - val_accuracy: 0.7692\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8310 - val_loss: 0.6298 - val_accuracy: 0.7692\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.8366 - val_loss: 0.6307 - val_accuracy: 0.7756\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3243 - accuracy: 0.8366 - val_loss: 0.6315 - val_accuracy: 0.7756\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3182 - accuracy: 0.8449 - val_loss: 0.6300 - val_accuracy: 0.7692\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8421 - val_loss: 0.6295 - val_accuracy: 0.7500\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8587 - val_loss: 0.6289 - val_accuracy: 0.7564\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8504 - val_loss: 0.6352 - val_accuracy: 0.7500\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2992 - accuracy: 0.8532 - val_loss: 0.6303 - val_accuracy: 0.7821\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.8781 - val_loss: 0.6283 - val_accuracy: 0.7821\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2862 - accuracy: 0.8837 - val_loss: 0.6329 - val_accuracy: 0.7756\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2797 - accuracy: 0.8947 - val_loss: 0.6358 - val_accuracy: 0.7821\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2775 - accuracy: 0.8892 - val_loss: 0.6420 - val_accuracy: 0.7821\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2685 - accuracy: 0.8947 - val_loss: 0.6384 - val_accuracy: 0.7885\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2650 - accuracy: 0.8920 - val_loss: 0.6378 - val_accuracy: 0.7692\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2571 - accuracy: 0.8975 - val_loss: 0.6407 - val_accuracy: 0.7821\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2536 - accuracy: 0.8947 - val_loss: 0.6413 - val_accuracy: 0.7756\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2474 - accuracy: 0.9169 - val_loss: 0.6341 - val_accuracy: 0.7692\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.2434 - accuracy: 0.9058 - val_loss: 0.6332 - val_accuracy: 0.7564\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2404 - accuracy: 0.9086 - val_loss: 0.6362 - val_accuracy: 0.7692\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2322 - accuracy: 0.9086 - val_loss: 0.6398 - val_accuracy: 0.7628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2248 - accuracy: 0.9114 - val_loss: 0.6439 - val_accuracy: 0.7564\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2214 - accuracy: 0.9169 - val_loss: 0.6428 - val_accuracy: 0.7564\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.2148 - accuracy: 0.9141 - val_loss: 0.6464 - val_accuracy: 0.7564\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2100 - accuracy: 0.9224 - val_loss: 0.6531 - val_accuracy: 0.7628\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2056 - accuracy: 0.9252 - val_loss: 0.6584 - val_accuracy: 0.7628\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2018 - accuracy: 0.9197 - val_loss: 0.6601 - val_accuracy: 0.7692\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1985 - accuracy: 0.9197 - val_loss: 0.6623 - val_accuracy: 0.7756\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1937 - accuracy: 0.9197 - val_loss: 0.6651 - val_accuracy: 0.7692\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1903 - accuracy: 0.9224 - val_loss: 0.6705 - val_accuracy: 0.7756\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1862 - accuracy: 0.9280 - val_loss: 0.6783 - val_accuracy: 0.7692\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1835 - accuracy: 0.9252 - val_loss: 0.6887 - val_accuracy: 0.7821\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1807 - accuracy: 0.9252 - val_loss: 0.6882 - val_accuracy: 0.7821\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1738 - accuracy: 0.9335 - val_loss: 0.6890 - val_accuracy: 0.7692\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1685 - accuracy: 0.9363 - val_loss: 0.6895 - val_accuracy: 0.7756\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1671 - accuracy: 0.9363 - val_loss: 0.7015 - val_accuracy: 0.7692\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1633 - accuracy: 0.9307 - val_loss: 0.7052 - val_accuracy: 0.7628\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1611 - accuracy: 0.9391 - val_loss: 0.7159 - val_accuracy: 0.7500\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1581 - accuracy: 0.9335 - val_loss: 0.7203 - val_accuracy: 0.7372\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1555 - accuracy: 0.9418 - val_loss: 0.7186 - val_accuracy: 0.7436\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1519 - accuracy: 0.9363 - val_loss: 0.7198 - val_accuracy: 0.7436\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1493 - accuracy: 0.9474 - val_loss: 0.7260 - val_accuracy: 0.7564\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1508 - accuracy: 0.9391 - val_loss: 0.7362 - val_accuracy: 0.7500\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1442 - accuracy: 0.9446 - val_loss: 0.7426 - val_accuracy: 0.7500\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1406 - accuracy: 0.9446 - val_loss: 0.7402 - val_accuracy: 0.7436\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1361 - accuracy: 0.9446 - val_loss: 0.7582 - val_accuracy: 0.7436\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1340 - accuracy: 0.9474 - val_loss: 0.7657 - val_accuracy: 0.7436\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9501 - val_loss: 0.7660 - val_accuracy: 0.7500\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1293 - accuracy: 0.9446 - val_loss: 0.7689 - val_accuracy: 0.7500\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.9529 - val_loss: 0.7650 - val_accuracy: 0.7628\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.9529 - val_loss: 0.7764 - val_accuracy: 0.7436\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1243 - accuracy: 0.9501 - val_loss: 0.7758 - val_accuracy: 0.7436\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1201 - accuracy: 0.9612 - val_loss: 0.7976 - val_accuracy: 0.7372\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9557 - val_loss: 0.8057 - val_accuracy: 0.7372\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9501 - val_loss: 0.8071 - val_accuracy: 0.7436\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9668 - val_loss: 0.8160 - val_accuracy: 0.7436\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9695 - val_loss: 0.8153 - val_accuracy: 0.7436\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9723 - val_loss: 0.8190 - val_accuracy: 0.7436\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9612 - val_loss: 0.8241 - val_accuracy: 0.7564\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1071 - accuracy: 0.9557 - val_loss: 0.8307 - val_accuracy: 0.7372\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.9695 - val_loss: 0.8299 - val_accuracy: 0.7564\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9751 - val_loss: 0.8394 - val_accuracy: 0.7564\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1009 - accuracy: 0.9612 - val_loss: 0.8498 - val_accuracy: 0.7628\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9751 - val_loss: 0.8519 - val_accuracy: 0.7564\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9778 - val_loss: 0.8580 - val_accuracy: 0.7564\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9695 - val_loss: 0.8621 - val_accuracy: 0.7628\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9751 - val_loss: 0.8698 - val_accuracy: 0.7564\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9751 - val_loss: 0.8704 - val_accuracy: 0.7564\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9751 - val_loss: 0.8797 - val_accuracy: 0.7564\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9778 - val_loss: 0.8892 - val_accuracy: 0.7564\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9778 - val_loss: 0.8918 - val_accuracy: 0.7564\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9806 - val_loss: 0.8928 - val_accuracy: 0.7564\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.9778 - val_loss: 0.8896 - val_accuracy: 0.7628\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9778 - val_loss: 0.8863 - val_accuracy: 0.7628\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9723 - val_loss: 0.9001 - val_accuracy: 0.7628\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9806 - val_loss: 0.9076 - val_accuracy: 0.7564\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9834 - val_loss: 0.9174 - val_accuracy: 0.7500\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9778 - val_loss: 0.9256 - val_accuracy: 0.7628\n",
      "Epoch 116/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9806 - val_loss: 0.9278 - val_accuracy: 0.7628\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9834 - val_loss: 0.9342 - val_accuracy: 0.7628\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9806 - val_loss: 0.9345 - val_accuracy: 0.7628\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9806 - val_loss: 0.9476 - val_accuracy: 0.7628\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.9834 - val_loss: 0.9495 - val_accuracy: 0.7628\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.9861 - val_loss: 0.9562 - val_accuracy: 0.7628\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9889 - val_loss: 0.9553 - val_accuracy: 0.7628\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9889 - val_loss: 0.9539 - val_accuracy: 0.7564\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9834 - val_loss: 0.9779 - val_accuracy: 0.7628\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9834 - val_loss: 0.9778 - val_accuracy: 0.7628\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9861 - val_loss: 0.9718 - val_accuracy: 0.7628\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9889 - val_loss: 0.9822 - val_accuracy: 0.7564\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0584 - accuracy: 0.9834 - val_loss: 0.9863 - val_accuracy: 0.7628\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9917 - val_loss: 0.9858 - val_accuracy: 0.7628\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0576 - accuracy: 0.9834 - val_loss: 0.9872 - val_accuracy: 0.7628\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9945 - val_loss: 0.9924 - val_accuracy: 0.7692\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9861 - val_loss: 1.0009 - val_accuracy: 0.7628\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9917 - val_loss: 0.9967 - val_accuracy: 0.7628\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0530 - accuracy: 0.9889 - val_loss: 1.0015 - val_accuracy: 0.7692\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9889 - val_loss: 1.0066 - val_accuracy: 0.7692\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9861 - val_loss: 1.0090 - val_accuracy: 0.7692\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0525 - accuracy: 0.9972 - val_loss: 1.0075 - val_accuracy: 0.7756\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9889 - val_loss: 1.0202 - val_accuracy: 0.7692\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9889 - val_loss: 1.0215 - val_accuracy: 0.7756\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9945 - val_loss: 1.0241 - val_accuracy: 0.7756\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9917 - val_loss: 1.0248 - val_accuracy: 0.7756\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0430 - accuracy: 0.9917 - val_loss: 1.0305 - val_accuracy: 0.7756\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9917 - val_loss: 1.0192 - val_accuracy: 0.7692\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0413 - accuracy: 0.9917 - val_loss: 1.0346 - val_accuracy: 0.7756\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9917 - val_loss: 1.0417 - val_accuracy: 0.7692\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9945 - val_loss: 1.0395 - val_accuracy: 0.7756\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9917 - val_loss: 1.0456 - val_accuracy: 0.7756\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9917 - val_loss: 1.0495 - val_accuracy: 0.7692\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9972 - val_loss: 1.0513 - val_accuracy: 0.7756\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9945 - val_loss: 1.0576 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20cbb0b63a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "923b9672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.9284\n",
      "accuracy: 92.84%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "score = model.evaluate(X,Y)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efddb4f",
   "metadata": {},
   "source": [
    "# Iteration 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d71836a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 2s 19ms/step - loss: 3.7603 - accuracy: 0.7562 - val_loss: 4.9612 - val_accuracy: 0.6731\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9648 - val_accuracy: 0.6731\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 4.9653 - val_accuracy: 0.6731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20cc3e8b4f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='sigmoid'))\n",
    "model.add(Dense(8,activation='sigmoid'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=100, batch_size=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21290d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 4.1238 - accuracy: 0.7311\n",
      "accuracy: 73.11%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969c923",
   "metadata": {},
   "source": [
    "# Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdd64b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 2s 19ms/step - loss: 2.7675 - accuracy: 0.4681 - val_loss: 2.0424 - val_accuracy: 0.6282\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.8615 - accuracy: 0.5596 - val_loss: 1.6970 - val_accuracy: 0.6218\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4184 - accuracy: 0.6039 - val_loss: 1.4188 - val_accuracy: 0.6410\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2607 - accuracy: 0.6620 - val_loss: 1.4964 - val_accuracy: 0.6154\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0654 - accuracy: 0.6953 - val_loss: 1.4894 - val_accuracy: 0.6218\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9801 - accuracy: 0.7091 - val_loss: 1.5011 - val_accuracy: 0.6410\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9579 - accuracy: 0.7202 - val_loss: 1.4273 - val_accuracy: 0.6538\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9452 - accuracy: 0.7313 - val_loss: 1.4348 - val_accuracy: 0.6538\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9023 - accuracy: 0.7396 - val_loss: 1.6277 - val_accuracy: 0.6538\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8496 - accuracy: 0.7535 - val_loss: 1.7580 - val_accuracy: 0.6474\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8324 - accuracy: 0.7590 - val_loss: 1.7788 - val_accuracy: 0.6410\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8239 - accuracy: 0.7673 - val_loss: 1.8309 - val_accuracy: 0.6474\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7659 - accuracy: 0.7618 - val_loss: 1.5881 - val_accuracy: 0.6410\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7199 - accuracy: 0.7535 - val_loss: 1.5305 - val_accuracy: 0.6410\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7122 - accuracy: 0.7618 - val_loss: 1.6669 - val_accuracy: 0.6538\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.7756 - val_loss: 1.8333 - val_accuracy: 0.6603\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.7756 - val_loss: 1.8417 - val_accuracy: 0.6538\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.7839 - val_loss: 1.9119 - val_accuracy: 0.6538\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6812 - accuracy: 0.7784 - val_loss: 1.9138 - val_accuracy: 0.6474\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.7839 - val_loss: 1.9900 - val_accuracy: 0.6410\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6722 - accuracy: 0.7812 - val_loss: 1.9308 - val_accuracy: 0.6474\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6671 - accuracy: 0.7812 - val_loss: 1.9220 - val_accuracy: 0.6538\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6626 - accuracy: 0.7812 - val_loss: 1.9211 - val_accuracy: 0.6538\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6292 - accuracy: 0.7839 - val_loss: 2.3277 - val_accuracy: 0.6731\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6177 - accuracy: 0.7895 - val_loss: 2.2523 - val_accuracy: 0.6603\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6107 - accuracy: 0.7867 - val_loss: 2.1094 - val_accuracy: 0.6603\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6062 - accuracy: 0.7950 - val_loss: 2.0384 - val_accuracy: 0.6538\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.7950 - val_loss: 1.9646 - val_accuracy: 0.6603\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6021 - accuracy: 0.7895 - val_loss: 1.9063 - val_accuracy: 0.6538\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5993 - accuracy: 0.7922 - val_loss: 1.8815 - val_accuracy: 0.6603\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5979 - accuracy: 0.7922 - val_loss: 2.1233 - val_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5962 - accuracy: 0.7922 - val_loss: 2.0545 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.7950 - val_loss: 1.9366 - val_accuracy: 0.6603\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5898 - accuracy: 0.8006 - val_loss: 1.9394 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5884 - accuracy: 0.8033 - val_loss: 1.9279 - val_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5861 - accuracy: 0.8116 - val_loss: 1.8830 - val_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.8061 - val_loss: 1.9195 - val_accuracy: 0.6603\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5520 - accuracy: 0.8089 - val_loss: 2.0967 - val_accuracy: 0.6795\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.8061 - val_loss: 2.0105 - val_accuracy: 0.6859\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.8089 - val_loss: 1.9864 - val_accuracy: 0.6795\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.8116 - val_loss: 1.9869 - val_accuracy: 0.6731\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5326 - accuracy: 0.8116 - val_loss: 2.0494 - val_accuracy: 0.6795\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.8116 - val_loss: 1.9735 - val_accuracy: 0.6795\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5291 - accuracy: 0.8089 - val_loss: 1.9078 - val_accuracy: 0.6795\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.8116 - val_loss: 1.8986 - val_accuracy: 0.6923\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.8089 - val_loss: 1.8896 - val_accuracy: 0.6923\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.8144 - val_loss: 1.8872 - val_accuracy: 0.6731\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.8144 - val_loss: 1.8896 - val_accuracy: 0.6731\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5188 - accuracy: 0.8116 - val_loss: 1.8880 - val_accuracy: 0.6731\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.8172 - val_loss: 1.8850 - val_accuracy: 0.6603\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.8172 - val_loss: 1.8913 - val_accuracy: 0.6731\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5133 - accuracy: 0.8144 - val_loss: 1.9634 - val_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5121 - accuracy: 0.8144 - val_loss: 1.9630 - val_accuracy: 0.6603\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.8144 - val_loss: 1.8839 - val_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5082 - accuracy: 0.8172 - val_loss: 1.8850 - val_accuracy: 0.6731\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.8172 - val_loss: 1.9154 - val_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.8172 - val_loss: 1.8067 - val_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.8255 - val_loss: 1.8024 - val_accuracy: 0.6603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.8227 - val_loss: 1.8893 - val_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.8227 - val_loss: 1.9210 - val_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.8227 - val_loss: 1.8649 - val_accuracy: 0.6603\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.8227 - val_loss: 1.8684 - val_accuracy: 0.6603\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.8227 - val_loss: 1.8722 - val_accuracy: 0.6603\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.8172 - val_loss: 1.8631 - val_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.8310 - val_loss: 1.7779 - val_accuracy: 0.6603\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.8338 - val_loss: 1.7951 - val_accuracy: 0.6603\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.8283 - val_loss: 1.8777 - val_accuracy: 0.6603\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.8366 - val_loss: 1.8078 - val_accuracy: 0.6538\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.8366 - val_loss: 1.7890 - val_accuracy: 0.6538\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.8338 - val_loss: 1.8176 - val_accuracy: 0.6538\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.8366 - val_loss: 1.8174 - val_accuracy: 0.6603\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4810 - accuracy: 0.8338 - val_loss: 1.9401 - val_accuracy: 0.6538\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.8310 - val_loss: 1.9418 - val_accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4782 - accuracy: 0.8310 - val_loss: 1.8632 - val_accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4850 - accuracy: 0.8421 - val_loss: 1.7798 - val_accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.8393 - val_loss: 1.8705 - val_accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.8310 - val_loss: 1.8305 - val_accuracy: 0.6667\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.8338 - val_loss: 1.9616 - val_accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.8393 - val_loss: 2.0086 - val_accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.8393 - val_loss: 2.0032 - val_accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.8421 - val_loss: 1.8735 - val_accuracy: 0.6731\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4640 - accuracy: 0.8421 - val_loss: 2.0306 - val_accuracy: 0.6731\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4668 - accuracy: 0.8310 - val_loss: 2.0230 - val_accuracy: 0.6731\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4617 - accuracy: 0.8421 - val_loss: 2.0191 - val_accuracy: 0.6731\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.8421 - val_loss: 2.0168 - val_accuracy: 0.6795\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.8449 - val_loss: 2.0205 - val_accuracy: 0.6731\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.8421 - val_loss: 2.0860 - val_accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4537 - accuracy: 0.8449 - val_loss: 2.0800 - val_accuracy: 0.6731\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4522 - accuracy: 0.8366 - val_loss: 2.0814 - val_accuracy: 0.6731\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.8532 - val_loss: 2.0772 - val_accuracy: 0.6795\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.8476 - val_loss: 2.0759 - val_accuracy: 0.6731\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.8560 - val_loss: 2.0745 - val_accuracy: 0.6795\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.8587 - val_loss: 2.0702 - val_accuracy: 0.6859\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8698 - val_loss: 2.0081 - val_accuracy: 0.6923\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.8670 - val_loss: 2.0711 - val_accuracy: 0.6923\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6510 - accuracy: 0.8421 - val_loss: 1.8755 - val_accuracy: 0.6090\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6468 - accuracy: 0.8172 - val_loss: 1.6882 - val_accuracy: 0.6795\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8393 - val_loss: 1.4805 - val_accuracy: 0.6859\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8476 - val_loss: 1.5514 - val_accuracy: 0.6859\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8476 - val_loss: 1.5508 - val_accuracy: 0.6923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20cc5221610>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=100, batch_size=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13758817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7506 - accuracy: 0.7969\n",
      "accuracy: 79.69%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b12724",
   "metadata": {},
   "source": [
    "# Iteration 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "116fd235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 2s 16ms/step - loss: 3.6929 - accuracy: 0.7562 - val_loss: 5.0431 - val_accuracy: 0.6731\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 3.6844 - accuracy: 0.7562 - val_loss: 5.0431 - val_accuracy: 0.6731\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 3.6836 - accuracy: 0.7562 - val_loss: 5.0431 - val_accuracy: 0.6731\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 3.6831 - accuracy: 0.7562 - val_loss: 5.0431 - val_accuracy: 0.6731\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 3.6826 - accuracy: 0.7562 - val_loss: 5.0430 - val_accuracy: 0.6731\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 3.6822 - accuracy: 0.7562 - val_loss: 5.0430 - val_accuracy: 0.6731\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 3.6820 - accuracy: 0.7562 - val_loss: 5.0431 - val_accuracy: 0.6731\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 3.6815 - accuracy: 0.7562 - val_loss: 5.0432 - val_accuracy: 0.6731\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 3.4239 - accuracy: 0.7590 - val_loss: 4.8072 - val_accuracy: 0.6731\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 3.2519 - accuracy: 0.7618 - val_loss: 4.7389 - val_accuracy: 0.6731\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.9567 - accuracy: 0.7618 - val_loss: 4.5820 - val_accuracy: 0.6731\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.7649 - accuracy: 0.7618 - val_loss: 4.5643 - val_accuracy: 0.6731\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.4760 - accuracy: 0.7673 - val_loss: 4.4873 - val_accuracy: 0.6731\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.4289 - accuracy: 0.7729 - val_loss: 4.4820 - val_accuracy: 0.6731\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 2.4223 - accuracy: 0.7756 - val_loss: 4.4834 - val_accuracy: 0.6731\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.4190 - accuracy: 0.7756 - val_loss: 4.4842 - val_accuracy: 0.6731\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.3832 - accuracy: 0.7756 - val_loss: 4.4821 - val_accuracy: 0.6731\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.3720 - accuracy: 0.7756 - val_loss: 4.4804 - val_accuracy: 0.6731\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.3682 - accuracy: 0.7756 - val_loss: 4.4820 - val_accuracy: 0.6731\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.3652 - accuracy: 0.7756 - val_loss: 4.5506 - val_accuracy: 0.6731\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.3625 - accuracy: 0.7784 - val_loss: 4.5508 - val_accuracy: 0.6731\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.3608 - accuracy: 0.7784 - val_loss: 4.5526 - val_accuracy: 0.6731\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.3370 - accuracy: 0.7812 - val_loss: 4.3272 - val_accuracy: 0.6731\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.2813 - accuracy: 0.7867 - val_loss: 4.1994 - val_accuracy: 0.6731\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.2757 - accuracy: 0.7922 - val_loss: 4.1969 - val_accuracy: 0.6731\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.2738 - accuracy: 0.7922 - val_loss: 4.1987 - val_accuracy: 0.6731\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.2719 - accuracy: 0.7922 - val_loss: 4.1981 - val_accuracy: 0.6731\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.2704 - accuracy: 0.7922 - val_loss: 4.1997 - val_accuracy: 0.6731\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.2693 - accuracy: 0.7922 - val_loss: 4.1988 - val_accuracy: 0.6731\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.2680 - accuracy: 0.7922 - val_loss: 4.2005 - val_accuracy: 0.6731\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.1100 - accuracy: 0.7895 - val_loss: 4.0232 - val_accuracy: 0.6731\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0915 - accuracy: 0.7895 - val_loss: 4.0291 - val_accuracy: 0.6731\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0860 - accuracy: 0.7895 - val_loss: 4.0567 - val_accuracy: 0.6731\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0838 - accuracy: 0.7867 - val_loss: 4.1208 - val_accuracy: 0.6731\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0804 - accuracy: 0.7867 - val_loss: 4.0508 - val_accuracy: 0.6731\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0782 - accuracy: 0.7867 - val_loss: 4.0599 - val_accuracy: 0.6731\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0772 - accuracy: 0.7867 - val_loss: 4.1230 - val_accuracy: 0.6731\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0753 - accuracy: 0.7895 - val_loss: 4.1265 - val_accuracy: 0.6731\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0731 - accuracy: 0.7895 - val_loss: 4.1325 - val_accuracy: 0.6731\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0718 - accuracy: 0.7895 - val_loss: 4.1287 - val_accuracy: 0.6731\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0701 - accuracy: 0.7895 - val_loss: 4.1354 - val_accuracy: 0.6731\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0689 - accuracy: 0.7895 - val_loss: 4.1297 - val_accuracy: 0.6731\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0661 - accuracy: 0.7895 - val_loss: 4.0673 - val_accuracy: 0.6731\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0638 - accuracy: 0.7895 - val_loss: 4.1302 - val_accuracy: 0.6731\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0620 - accuracy: 0.7895 - val_loss: 4.0458 - val_accuracy: 0.6731\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 2.0598 - accuracy: 0.7895 - val_loss: 4.0475 - val_accuracy: 0.6731\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0585 - accuracy: 0.7895 - val_loss: 4.0392 - val_accuracy: 0.6731\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0562 - accuracy: 0.7895 - val_loss: 4.0369 - val_accuracy: 0.6731\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0537 - accuracy: 0.7895 - val_loss: 4.0376 - val_accuracy: 0.6731\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.0517 - accuracy: 0.7895 - val_loss: 4.0318 - val_accuracy: 0.6731\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0502 - accuracy: 0.7895 - val_loss: 4.0346 - val_accuracy: 0.6731\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0498 - accuracy: 0.7895 - val_loss: 3.9791 - val_accuracy: 0.6731\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0479 - accuracy: 0.7895 - val_loss: 3.9654 - val_accuracy: 0.6731\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0473 - accuracy: 0.7895 - val_loss: 3.9652 - val_accuracy: 0.6731\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0445 - accuracy: 0.7895 - val_loss: 3.9695 - val_accuracy: 0.6731\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0433 - accuracy: 0.7922 - val_loss: 3.9846 - val_accuracy: 0.6731\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0408 - accuracy: 0.7922 - val_loss: 3.9861 - val_accuracy: 0.6731\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.0393 - accuracy: 0.7922 - val_loss: 4.0247 - val_accuracy: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0379 - accuracy: 0.7922 - val_loss: 4.0203 - val_accuracy: 0.6731\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0054 - accuracy: 0.7922 - val_loss: 3.9483 - val_accuracy: 0.6731\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.9991 - accuracy: 0.7950 - val_loss: 3.9322 - val_accuracy: 0.6731\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.9982 - accuracy: 0.7922 - val_loss: 3.9357 - val_accuracy: 0.6731\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.9948 - accuracy: 0.7950 - val_loss: 3.9359 - val_accuracy: 0.6731\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.9944 - accuracy: 0.7950 - val_loss: 3.9377 - val_accuracy: 0.6731\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.9921 - accuracy: 0.7950 - val_loss: 4.0072 - val_accuracy: 0.6731\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.9909 - accuracy: 0.7978 - val_loss: 4.0085 - val_accuracy: 0.6731\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.9894 - accuracy: 0.7978 - val_loss: 3.9524 - val_accuracy: 0.6731\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.9883 - accuracy: 0.7978 - val_loss: 4.0054 - val_accuracy: 0.6731\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.9865 - accuracy: 0.7978 - val_loss: 4.0041 - val_accuracy: 0.6731\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9848 - accuracy: 0.7978 - val_loss: 4.0029 - val_accuracy: 0.6731\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9839 - accuracy: 0.7978 - val_loss: 4.0007 - val_accuracy: 0.6731\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9928 - accuracy: 0.8006 - val_loss: 3.9968 - val_accuracy: 0.6731\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9846 - accuracy: 0.8006 - val_loss: 3.9977 - val_accuracy: 0.6731\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9805 - accuracy: 0.8006 - val_loss: 3.9973 - val_accuracy: 0.6731\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9786 - accuracy: 0.7978 - val_loss: 3.9986 - val_accuracy: 0.6731\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.9805 - accuracy: 0.8006 - val_loss: 3.9965 - val_accuracy: 0.6731\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9783 - accuracy: 0.8006 - val_loss: 3.9974 - val_accuracy: 0.6731\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9767 - accuracy: 0.8006 - val_loss: 3.9954 - val_accuracy: 0.6731\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9743 - accuracy: 0.8033 - val_loss: 3.9955 - val_accuracy: 0.6731\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9729 - accuracy: 0.8033 - val_loss: 3.9942 - val_accuracy: 0.6731\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9713 - accuracy: 0.8061 - val_loss: 3.9936 - val_accuracy: 0.6731\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9698 - accuracy: 0.8033 - val_loss: 3.9927 - val_accuracy: 0.6731\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9684 - accuracy: 0.8061 - val_loss: 3.9926 - val_accuracy: 0.6731\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9681 - accuracy: 0.8116 - val_loss: 3.9280 - val_accuracy: 0.6731\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9663 - accuracy: 0.8144 - val_loss: 3.9201 - val_accuracy: 0.6731\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9652 - accuracy: 0.8116 - val_loss: 3.9182 - val_accuracy: 0.6731\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9632 - accuracy: 0.8144 - val_loss: 3.9156 - val_accuracy: 0.6731\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9619 - accuracy: 0.8172 - val_loss: 3.9107 - val_accuracy: 0.6667\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9596 - accuracy: 0.8199 - val_loss: 3.9106 - val_accuracy: 0.6667\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9602 - accuracy: 0.8172 - val_loss: 3.9066 - val_accuracy: 0.6667\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9571 - accuracy: 0.8199 - val_loss: 3.9064 - val_accuracy: 0.6667\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9562 - accuracy: 0.8172 - val_loss: 3.9040 - val_accuracy: 0.6731\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.9546 - accuracy: 0.8172 - val_loss: 3.9018 - val_accuracy: 0.6731\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.9537 - accuracy: 0.8172 - val_loss: 3.8297 - val_accuracy: 0.6667\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9516 - accuracy: 0.8172 - val_loss: 3.8280 - val_accuracy: 0.6667\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9495 - accuracy: 0.8172 - val_loss: 3.8275 - val_accuracy: 0.6731\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9508 - accuracy: 0.8199 - val_loss: 3.8134 - val_accuracy: 0.6731\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9474 - accuracy: 0.8172 - val_loss: 3.8131 - val_accuracy: 0.6731\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.9472 - accuracy: 0.8227 - val_loss: 3.8133 - val_accuracy: 0.6667\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9521 - accuracy: 0.8255 - val_loss: 3.8109 - val_accuracy: 0.6667\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9461 - accuracy: 0.8227 - val_loss: 3.8127 - val_accuracy: 0.6667\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9418 - accuracy: 0.8255 - val_loss: 3.8102 - val_accuracy: 0.6667\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.9150 - accuracy: 0.8283 - val_loss: 3.5866 - val_accuracy: 0.6667\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.6500 - accuracy: 0.8255 - val_loss: 2.7305 - val_accuracy: 0.6731\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5933 - accuracy: 0.8283 - val_loss: 2.8349 - val_accuracy: 0.6731\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5747 - accuracy: 0.8227 - val_loss: 2.9435 - val_accuracy: 0.6859\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5687 - accuracy: 0.8310 - val_loss: 2.9446 - val_accuracy: 0.6859\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5663 - accuracy: 0.8393 - val_loss: 2.9407 - val_accuracy: 0.6923\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5586 - accuracy: 0.8393 - val_loss: 2.9387 - val_accuracy: 0.6923\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.5547 - accuracy: 0.8310 - val_loss: 2.9381 - val_accuracy: 0.6859\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.5508 - accuracy: 0.8338 - val_loss: 2.9360 - val_accuracy: 0.6859\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5500 - accuracy: 0.8393 - val_loss: 2.9358 - val_accuracy: 0.6859\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5450 - accuracy: 0.8393 - val_loss: 2.8646 - val_accuracy: 0.6859\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.5435 - accuracy: 0.8366 - val_loss: 2.8788 - val_accuracy: 0.6795\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5414 - accuracy: 0.8338 - val_loss: 2.9319 - val_accuracy: 0.6795\n",
      "Epoch 116/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.5374 - accuracy: 0.8449 - val_loss: 2.9307 - val_accuracy: 0.6923\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.5051 - accuracy: 0.8421 - val_loss: 2.8339 - val_accuracy: 0.6987\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3848 - accuracy: 0.8504 - val_loss: 2.8321 - val_accuracy: 0.7051\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3802 - accuracy: 0.8449 - val_loss: 2.8341 - val_accuracy: 0.7051\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3768 - accuracy: 0.8476 - val_loss: 2.8347 - val_accuracy: 0.7051\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3734 - accuracy: 0.8476 - val_loss: 2.8352 - val_accuracy: 0.7051\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3708 - accuracy: 0.8476 - val_loss: 2.8335 - val_accuracy: 0.7051\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.3706 - accuracy: 0.8476 - val_loss: 2.7776 - val_accuracy: 0.7179\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3680 - accuracy: 0.8421 - val_loss: 2.7625 - val_accuracy: 0.7179\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3677 - accuracy: 0.8504 - val_loss: 2.7628 - val_accuracy: 0.7179\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3674 - accuracy: 0.8476 - val_loss: 2.7670 - val_accuracy: 0.7115\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3621 - accuracy: 0.8504 - val_loss: 2.7590 - val_accuracy: 0.7179\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3606 - accuracy: 0.8476 - val_loss: 2.7596 - val_accuracy: 0.7179\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3660 - accuracy: 0.8504 - val_loss: 2.7614 - val_accuracy: 0.7244\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.3595 - accuracy: 0.8476 - val_loss: 2.7600 - val_accuracy: 0.7179\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3556 - accuracy: 0.8504 - val_loss: 2.7586 - val_accuracy: 0.7179\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3562 - accuracy: 0.8532 - val_loss: 2.7566 - val_accuracy: 0.7179\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3544 - accuracy: 0.8560 - val_loss: 2.7570 - val_accuracy: 0.7179\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.3524 - accuracy: 0.8504 - val_loss: 2.7578 - val_accuracy: 0.7115\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.3210 - accuracy: 0.8504 - val_loss: 2.7659 - val_accuracy: 0.7115\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.2210 - accuracy: 0.8587 - val_loss: 2.7647 - val_accuracy: 0.6923\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.2071 - accuracy: 0.8560 - val_loss: 2.6859 - val_accuracy: 0.6859\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.1995 - accuracy: 0.8560 - val_loss: 2.6826 - val_accuracy: 0.6859\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1946 - accuracy: 0.8560 - val_loss: 2.6815 - val_accuracy: 0.6987\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1910 - accuracy: 0.8615 - val_loss: 2.6892 - val_accuracy: 0.6923\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.1889 - accuracy: 0.8587 - val_loss: 2.6991 - val_accuracy: 0.6923\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.1851 - accuracy: 0.8615 - val_loss: 2.7758 - val_accuracy: 0.6987\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1837 - accuracy: 0.8615 - val_loss: 2.8321 - val_accuracy: 0.6923\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1814 - accuracy: 0.8643 - val_loss: 2.8300 - val_accuracy: 0.6923\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1805 - accuracy: 0.8587 - val_loss: 2.8294 - val_accuracy: 0.6987\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.1796 - accuracy: 0.8615 - val_loss: 2.7666 - val_accuracy: 0.6923\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.1793 - accuracy: 0.8643 - val_loss: 2.7524 - val_accuracy: 0.7051\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.1774 - accuracy: 0.8615 - val_loss: 2.7525 - val_accuracy: 0.7051\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.1733 - accuracy: 0.8615 - val_loss: 2.7505 - val_accuracy: 0.7051\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1725 - accuracy: 0.8670 - val_loss: 2.7467 - val_accuracy: 0.7051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20cc6686ee0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2516c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6448 - accuracy: 0.8240\n",
      "accuracy: 82.40%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7232a",
   "metadata": {},
   "source": [
    "# Out of all the 4 Iterations we are getting best accuracy with Iteration 1 - 94.78%. So we can go ahead with those combinations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
